{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass \n",
    "from torch import nn \n",
    "import torch.nn.functional as F \n",
    "import math, torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass \n",
    "class ModelArgs:\n",
    "    n_heads: int = 32\n",
    "    dim: int = 4096\n",
    "    n_kv_heads:int = 8\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat_kv(x, reps):\n",
    "    bsz, seqlen, n_heads, dims = x.shape\n",
    "    if reps == 1:\n",
    "        return x \n",
    "    return (x[:,:,:,None,:]\n",
    "            .expand(bsz, seqlen, n_heads, reps, dims)\n",
    "            .reshape(bsz, seqlen, n_heads*reps, dims))\n",
    "\n",
    "def apply_rope(k,v):\n",
    "    return k,v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GQA(nn.Module):\n",
    "    def __init__(self, args:ModelArgs):\n",
    "        super().__init__()\n",
    "        self.args = args\n",
    "        head_dim = args.dim // args.n_heads\n",
    "        self.head_dim = head_dim\n",
    "        self.wq = nn.Parameter(torch.FloatTensor((args.dim, args.n_heads*head_dim)))\n",
    "        self.wk = nn.Parameter(torch.FloatTensor((args.dim, args.n_kv_heads*head_dim)))\n",
    "        self.wv = nn.Parameter(torch.FloatTensor((args.dim, args.n_kv_heads*head_dim)))\n",
    "        self.wo = nn.Parameter(torch.FloatTensor((args.n_kv_heads*head_dim, args.dim)))\n",
    "        self.reps = args.n_heads // args.n_kv_heads\n",
    "\n",
    "\n",
    "    def forward(self, x, mask:None):\n",
    "        bsz, seqlen, _ = x.shape\n",
    "        xq = self.wq(x).reshape(bsz, seqlen, self.args.n_heads, self.head_dim).transpose(1,2)\n",
    "        xk = self.wk(x).reshape(bsz, seqlen, self.args.n_kv_heads, self.head_dim).transpose(1,2)\n",
    "        xv = self.wv(x).reshape(bsz, seqlen, self.args.n_kv_heads, self.head_dim).transpose(1,2)\n",
    "        keys, values = apply_rope(keys, values)\n",
    "        keys, values = repeat_kv(xk, self.reps), repeat_kv(xv, self.reps)\n",
    "\n",
    "        #计算\n",
    "        score = torch.matmul(xq, keys.transpose(2,3))\n",
    "        if mask:\n",
    "            score = score + mask\n",
    "        score = F.softmax(score, dim=-1) / math.sqrt(self.head_dim)\n",
    "\n",
    "        output = torch.matmul(score, values)\n",
    "        output = output.transpose(1,2).contiguous().view(bsz, seqlen, self.args.n_kv_heads*self.head_dim)\n",
    "        return self.wo(output)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
